[ { "title": "My Traefik config with let's encrypt wildcards", "url": "/posts/traefik-le/", "categories": "homelab, traefik, let's encrypt", "tags": "reverse proxy, let's encrypt", "date": "2022-08-10 13:00:00 -0400", "snippet": "Install ansible and docker composeOn the control host install ansible sudo apt install ansible docker-compose -yRun Playbook---- hosts: all become: true tasks: - name: install pre-reqs apt: name: \"\" state: present with_items: - \"ca-certificates\" - \"curl\" - \"software-properties-common\" - \"docker-compose\" - name: docker repo key apt_key: url: https://download.docker.com/linux/ubuntu/gpg state: present - name: docker repo install apt_repository: repo: deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable state: present - name: install docker apt: name: docker-ce state: present update_cache: yes - name: start service service: name: docker state: started enabled: true- name: ensure docker-py is installed apt: name: \"\" state: present with_items: # - \"python-docker\" - \"python3-docker\"- name: add user to docker group user: name: ryan group: docker append: yesMake data directory for traefikmkdir /data/traefik_datachown -R user:userCreate the acme.json filecd /data/traefik_datatouch acme.jsonchmod 600 acme.jsonCreate traefik.ymltouch traefik.ymlCopy configapi: dashboard: true debug: trueentryPoints: http: address: \":80\" http: redirections: entryPoint: to: https scheme: https https: address: \":443\"serversTransport: insecureSkipVerify: trueproviders: docker: endpoint: \"unix:///var/run/docker.sock\" exposedByDefault: false file: filename: /config.ymlcertificatesResolvers: cloudflare: acme: email: EMAIL # the cloudflare account email storage: acme.json dnsChallenge: provider: cloudflare resolvers: - \"1.1.1.1:53\" - \"1.0.0.1:53\"Create config.ymlhttp: #region routers routers: proxmox: entryPoints: - \"https\" rule: \"Host(`hype.example.net`)\" middlewares: - default-headers - middlewares-https-redirectscheme tls: {} service: proxmox pihole: entryPoints: - \"https\" rule: \"Host(`dns.example.net`)\" middlewares: - default-headers - addprefix-pihole - https-redirectscheme tls: {} service: pihole homeassistant: # For Homeassistant config, check: https://www.home-assistant.io/integrations/http/#reverse-proxies # This relies on Homeassistant using http. No certs are needed in the Homeassistant config. entryPoints: - \"https\" rule: \"Host(`ha.example.net`)\" middlewares: - default-headers - https-redirectscheme tls: {} service: homeassistant truenas: entryPoints: - \"https\" rule: \"Host(`sandrock.example.net`)\" middlewares: - default-headers - https-redirectscheme tls: {} service: truenas plex: entryPoints: - \"https\" rule: \"Host(`plex.example.net`)\" middlewares: - default-headers - https-redirectscheme tls: {} service: plex opnsense: entryPoints: - \"https\"fw.example.net`)\" middlewares: - default-headers - https-redirectscheme tls: {} service: opnsense pterodactyl: entryPoints: - \"https\" rule: \"Host(`game-server.example.net`)\" middlewares: - default-headers - https-redirectscheme tls: {} service: pterodactyl#endregion#region services services: proxmox: loadBalancer: servers: - url: \"https://10.0.3.195:8006\" passHostHeader: true pihole: loadBalancer: servers: - url: \"http://10.0.3.253:80\" - url: \"http://10.0.3.251:80\" passHostHeader: true homeassistant: loadBalancer: servers: - url: \"http://10.0.3.250:8123\" passHostHeader: true truenas: loadBalancer: servers: - url: \"http://10.0.3.194\" passHostHeader: true plex: loadBalancer: servers: - url: \"http:10.0.3.190:32400\" passHostHeader: true opnsense: loadBalancer: servers: - url: \"https://10.0.2.1\" passHostHeader: true #pterodactyl: # loadBalancer: # servers: # - url: \"http://192.168.0.110:80\" # passHostHeader: true#endregion middlewares: addprefix-pihole: addPrefix: prefix: \"/admin\" middlewares-https-redirectscheme: redirectScheme: scheme: https permanent: true default-headers: headers: frameDeny: true browserXssFilter: true contentTypeNosniff: true forceSTSHeader: true stsIncludeSubdomains: true stsPreload: true stsSeconds: 15552000 customFrameOptionsValue: SAMEORIGIN customRequestHeaders: X-Forwarded-Proto: https default-whitelist: ipWhiteList: sourceRange: - \"10.0.0.0/8\" - \"192.168.0.0/16\" - \"172.16.0.0/12\" secured: chain: middlewares: - default-whitelist - default-headersFinally Copy the docker-compose.ymlvi docker-compose.ymlversion: '3'services: traefik: image: traefik:latest container_name: traefik restart: unless-stopped security_opt: - no-new-privileges:true networks: - proxy ports: - 80:80 - 443:443 environment: - CF_API_EMAIL=CF_EMAIL - CF_DNS_API_TOKEN=TF TOKEN # be sure to use the correct one depending on if you are using a token or key volumes: - /etc/localtime:/etc/localtime:ro - /var/run/docker.sock:/var/run/docker.sock:ro - /data/traefik_data/traefik.yml:/traefik.yml:ro - /data/traefik_data/acme.json:/acme.json - /data/traefik_data/config.yml:/config.yml:ro labels: - \"traefik.enable=true\" - \"traefik.http.routers.traefik.entrypoints=http\" - \"traefik.http.routers.traefik.rule=Host(`traefik-dash.example.com`)\" #- \"traefik.http.middlewares.traefik-auth.basicauth.users=user:password hash\" - \"traefik.http.middlewares.traefik-https-redirect.redirectscheme.scheme=https\" - \"traefik.http.middlewares.sslheader.headers.customrequestheaders.X-Forwarded-Proto=https\" - \"traefik.http.routers.traefik.middlewares=traefik-https-redirect\" - \"traefik.http.routers.traefik-secure.entrypoints=https\" - \"traefik.http.routers.traefik-secure.rule=Host(`traefik-dash.example.com`)\" #- \"traefik.http.routers.traefik-secure.middlewares=traefik-auth\" - \"traefik.http.routers.traefik-secure.tls=true\" - \"traefik.http.routers.traefik-secure.tls.certresolver=cloudflare\" - \"traefik.http.routers.traefik-secure.tls.domains[0].main=example.com\" - \"traefik.http.routers.traefik-secure.tls.domains[0].sans=*.example.com\" - \"traefik.http.routers.traefik-secure.service=api@internal\" networks: proxy: external: true" }, { "title": "Stand up Bookstack", "url": "/posts/backstack/", "categories": "homelab, docker, wiki", "tags": "bookstack, docker-compose", "date": "2022-07-10 13:00:00 -0400", "snippet": "Make config directorymkdir /data/bookstack_datamkdir /data/bookstack_db_dataCopy the compose file tovi /data/bookstack_data/docker-compose.ymlversion: \"3\"services: bookstack: image: lscr.io/linuxserver/bookstack container_name: bookstack environment: - PUID=1000 - PGID=1000 - DB_HOST=bookstack_db - DB_USER=bookstack - DB_PASS=DBPW - DB_DATABASE=bookstackapp volumes: - /data/bookstack_data:/config ports: - 6875:80 restart: unless-stopped depends_on: - bookstack_db bookstack_db: image: lscr.io/linuxserver/mariadb container_name: bookstack_db environment: - PUID=1000 - PGID=1000 - MYSQL_ROOT_PASSWORD=ROOTPW - TZ=America/New_York - MYSQL_DATABASE=bookstackapp - MYSQL_USER=bookstack - MYSQL_PASSWORD=DBPW volumes: - /data/bookstack_db_data:/config restart: unless-stopped" }, { "title": "Home labbin' IT 5 - Moving to Freenas", "url": "/posts/home-labbin-it-5/", "categories": "homelab, youtube", "tags": "home labbin' it", "date": "2018-03-30 13:00:00 -0400", "snippet": " This week we are talking about migrating from UNRAID to Freenas. Let’s start with the why. For about a year I’ve been using UNRAID as my storage/VM/docker platform and it’s been awesome. However like it says in the title, UNRAID is not raid, which has some good benefits and some pretty significant downsides. Because it doesn’t use RAID it means I can mix an match drive capacities at will without issue and can connect a drive to any computer that can read XFS have full access to the data. Downside is it’s not RAID. Because it’s really just a software managed JBOD it means that you pay some penalties, one big one is that it’s as fast as your slowest drive, and second because all the drives to don’t share the task of a given read or write you get pretty slow performance. You can mitigate this somewhat by adding a cache drive, typically an SSD, which accepts all the writes and runs a “mover job” once a day to write the data to the larger capacity spinning drives. But what happens if the cache drive fails? The answer is you lose all the data that was still resident on the cache, you can of course use multiple cache drives in a RAID 1 which would help a lot but still I don’t like this approach.I briefly looked at  Rockstor, which on the surface seems legit, relatively new great interface and an awesome plug-in system. What kept me from using Rockstor is it uses BTRFS. Using BTRFS isn’t an issue for me since it’s basically designed to the Linux equivalent of ZFS. The show stopper was that it currently doesn’t support RAID 5 or 6. It has support for it but it’s not recommended for production use because of a writ-hole bug. A write-hole basically is this, you save a piece of data to your array, the OS makes the necessary syscall to have the data committed to disk, the call is returned as successful, except nothing was actually written. Seems like a bad look when I’m depending on this system to store my data.I could have also done Xpenology but looking around at that eco-system it seems like it’s more effort that it’s worth.So I settled on Freenas, yes Freenas is a bit long in the tooth but it works, and works well, for storage at least, the other features such as virtualization work ok but they aren’t really top notch. Don’t even get me started on docker support. But because I had tons of RAM and an extra 256GB SSD laying around it worked out great. I get good performance because of the way ZFS works and having the SSD to work as a L2 Cache ( L2ARC) has been great." }, { "title": "Home Labbin' It 4", "url": "/posts/home-labbin-it-4/", "categories": "homelab, youtube", "tags": "home labbin' it", "date": "2018-03-17 13:00:00 -0400", "snippet": " A quick intro to the project and it’s goals. Building a 4U Nas for my lab to replay my R410 running Unraid. 15 drives mostly 8TB SAS drives I got from a client that was decommissioning some Storage arrays and had tons of brand new spares." }, { "title": "Home Labbin' It Episode 3 - Building a New Nas", "url": "/posts/home-labbin-it-3/", "categories": "homelab, youtube", "tags": "home labbin' it", "date": "2018-03-02 12:00:00 -0500", "snippet": " A quick intro to the project and it’s goals. Building a 4U Nas for my lab to replay my R410 running Unraid. 15 drives mostly 8TB SAS drives I got from a client that was decommissioning some Storage arrays and had tons of brand new spares." }, { "title": "Home Labin' It", "url": "/posts/Home-Labin'-It/", "categories": "homelab, youtube", "tags": "home labbin' it", "date": "2017-12-05 12:00:00 -0500", "snippet": " Today I decided to start a new web series on home labs. It’s designed for home lab enthusiasts, who like to get their hands dirty learning cool new tech. The first video is just an introduction to the content. Look out for more!" }, { "title": "Home Labin' It 2", "url": "/posts/home-labbin-it-2/", "categories": "homelab, youtube", "tags": "home labbin' it", "date": "2017-12-05 12:00:00 -0500", "snippet": " Quick video for those starting their home labs covering a very common question in the /r/homelab subreddit, “What Operating System should you use in your lab? Windows, Linux, Mac?” I very briefly discuss hypervisors and their benefits." } ]
